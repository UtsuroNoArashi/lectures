\documentclass{subfiles}
\begin{document}
    Let us recall that, given a code \(C\), 
    \(L_{S}(C)\) denotes the average code length of the codewords in \(C\).

    From this, we can define two other important quantities: 
        the efficiency and the redundancy of the code.
        Formally, the efficiency is defined as 
        \[
            \vartheta(C) = \frac{\entropy{S}[n]}{L_{S}(C)},
        \]
        which, according to Shannon's theorem, takes values in the range \([0, 1]\).
        The redundancy of the code is defined as 
        \[
            \rho(C) = 1 - \vartheta(C),
        \]
        where, when considering Huffman coding, 
            one can show that the redundancy approaches \(1\) as the probability 
            of the most frequent symbol approaches \(1\).

        This naturally leads to the question: can we do better than Huffman?
            The answer is affirmative, but it requires a completely different approach:
            instead of assigning a codeword to each symbol, we assign one to the entire text.
            The method we are about to present is known as \emph{\gls{ac}}.

        \subsection{The encoding}
        \subfile{../sub/3.1 - AC encoding}

        \subsection{The decoding}
        \subfile{../sub/3.2 - AC decoding}
       
        \subsection{The adaptive version}
        \subfile{../sub/3.3 - Adaptive AC}
        \subfile{../exercise/Exercises - Arithmetic coding}
\end{document}
